{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet33 for CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet33 for images CIFAR-10 3*32*32 = 3*1024\n",
    "#Resnet33 for images MNIST 1*28*28\n",
    "#import statements\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Data and preprocess\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "#trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "#                                        download=True, transform=transform)\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                       download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "#classes = ('plane', 'car', 'bird', 'cat',\n",
    "#           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "classes = ('0','1','2','3','4','5','6','7','8','9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "class residual_unit(torch.nn.Module):\n",
    "    def __init__(self, N, C, L, W, training=False):\n",
    "        super(residual_unit, self).__init__()\n",
    "        self.ru_conv1 = torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.ru_bn1 = torch.nn.BatchNorm1d(32, affine=training)\n",
    "        self.ru_act1 = torch.nn.ReLU()\n",
    "        self.ru_conv2 = torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.ru_bn2 = torch.nn.BatchNorm1d(32, affine=training)\n",
    "        self.ru_act2 = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.ru_conv1(x)\n",
    "        y = self.ru_bn1(y)\n",
    "        y = self.ru_act1(y)\n",
    "        y = self.ru_conv2(y)\n",
    "        y = self.ru_bn2(y)\n",
    "        y = y + x\n",
    "        y = self.ru_act2(y)\n",
    "        return y\n",
    "\n",
    "class residual_stack(torch.nn.Module):\n",
    "    def __init__(self, N, C, L, W, training=False):\n",
    "        super(residual_stack, self).__init__()\n",
    "        self.rs_conv1 = torch.nn.Conv1d(in_channels=C, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.rs_bn1 = torch.nn.BatchNorm1d(32, affine=training)\n",
    "        self.rs_ru1 = residual_unit(N, C, L, W, training) #Create an object of the custom nn model\n",
    "        self.rs_ru2 = residual_unit(N, C, L, W, training)\n",
    "        self.rs_mp1 = torch.nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.rs_conv1(x)\n",
    "        y = self.rs_bn1(y)\n",
    "        y = self.rs_ru1(y)\n",
    "        y = self.rs_ru2(y)\n",
    "        y = self.rs_mp1(y)\n",
    "        return y\n",
    "    \n",
    "class resnet33(torch.nn.Module):\n",
    "    def __init__(self, N, C, L, W, training=False):\n",
    "        super(resnet33, self).__init__()\n",
    "        self.rn33_rs1 = residual_stack(N, 3, 1024,1, training) #output is N*32*512\n",
    "        self.rn33_rs2 = residual_stack(N, 32, 512,1, training) #output is N*32*256\n",
    "        self.rn33_rs3 = residual_stack(N, 32, 256,1, training) #output is N*32*128\n",
    "        self.rn33_rs4 = residual_stack(N, 32, 128,1, training) #output is N*32*64\n",
    "        self.rn33_rs5 = residual_stack(N, 32, 64,1, training) #output is N*32*32\n",
    "        self.rn33_rs6 = residual_stack(N, 32, 32,1, training) #output is N*32*16\n",
    "        self.flat = torch.nn.Flatten() #output is N*512\n",
    "        self.fc1 = torch.nn.Linear(512, 128) #output is N*128\n",
    "        self.selu1 = torch.nn.SELU()\n",
    "        self.alphadrop1 = torch.nn.AlphaDropout(p=0.95)\n",
    "        self.fc2 = torch.nn.Linear(128, 128) #output is N*128\n",
    "        self.selu2 = torch.nn.SELU()\n",
    "        self.alphadrop2 = torch.nn.AlphaDropout(p=0.95)\n",
    "        self.fc3 = torch.nn.Linear(128, 10) #output is N*24\n",
    "        self.smx1 = torch.nn.Softmax(dim=1)#dimension\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print('input' + str(x.size()))\n",
    "        y = self.rn33_rs1(x)\n",
    "        #print(y.size())\n",
    "        y = self.rn33_rs2(y)\n",
    "        #print(y.size())\n",
    "        y = self.rn33_rs3(y)\n",
    "        #print(y.size())\n",
    "        y = self.rn33_rs4(y)\n",
    "        #print(y.size())\n",
    "        y = self.rn33_rs5(y)\n",
    "        #print(y.size())\n",
    "        y = self.rn33_rs6(y)\n",
    "        #print(y.size())\n",
    "        #85272 parameters\n",
    "        y = self.flat(y)\n",
    "        #print(y.size())\n",
    "        y = self.fc1(y)\n",
    "        y = self.selu1(y)\n",
    "        y = self.alphadrop1(y)\n",
    "        #print(y.size())\n",
    "        y = self.fc2(y)\n",
    "        y = self.selu2(y)\n",
    "        y = self.alphadrop2(y)\n",
    "        #print(y.size())\n",
    "        y = self.fc3(y)\n",
    "        y = self.smx1(y)\n",
    "        #print(y.size())\n",
    "        return y\n",
    "    \n",
    "class resnet33_new(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(resnet33_new, self).__init__() #Consider only 1 residual stack layer\n",
    "        self.conv1 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.maxpool = torch.nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.conv3 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.conv4 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.conv5 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        \n",
    "        self.conv6 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.conv7 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.conv8 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.conv9 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        \n",
    "        self.conv10 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.conv11 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.conv12 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.conv13 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        \n",
    "        self.conv14 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.conv15 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.conv16 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        self.conv17 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        \n",
    "        self.conv18 = torch.nn.Sequential(torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=1),torch.nn.BatchNorm1d(32))\n",
    "        \n",
    "        self.classifier = torch.nn.Sequential(torch.nn.Linear(512,128),\n",
    "                                        #torch.nn.SELU(True),\n",
    "                                        #torch.nn.AlphaDropout(p=0.95),\n",
    "                                        torch.nn.ReLU(True),\n",
    "                                        torch.nn.Linear(128,128),\n",
    "                                        #torch.nn.SELU(True),\n",
    "                                        #torch.nn.AlphaDropout(p=0.95), \n",
    "                                        torch.nn.ReLU(True),\n",
    "                                        torch.nn.Linear(128,10))\n",
    "                                        #torch.nn.Softmax(dim=1)) \n",
    "            \n",
    "    def forward(self,x):\n",
    "        #Residual Stack 1\n",
    "        y1 = F.relu(self.conv1(x)) #1'st layer con\n",
    "        y2 = F.relu(self.conv2(y1))\n",
    "        y3 = self.maxpool(F.relu(self.conv3(y2) + y1))\n",
    "        \n",
    "        #Residual Stack 2\n",
    "        y4 = self.conv4(y3)\n",
    "        y5 = F.relu(self.conv5(y4))\n",
    "        y6 = self.maxpool(F.relu(self.conv6(y5) + y4))\n",
    "        \n",
    "        #Residual Stack 3\n",
    "        y4 = self.conv7(y6)\n",
    "        y5 = F.relu(self.conv8(y4))\n",
    "        y6 = self.maxpool(F.relu(self.conv9(y5) + y4))\n",
    "        \n",
    "        #Residual Stack 4\n",
    "        y4 = self.conv10(y6)\n",
    "        y5 = F.relu(self.conv11(y4))\n",
    "        y6 = self.maxpool(F.relu(self.conv12(y5) + y4))\n",
    "        \n",
    "        #Residual Stack 5\n",
    "        y4 = self.conv13(y6)\n",
    "        y5 = F.relu(self.conv14(y4))\n",
    "        y6 = self.maxpool(F.relu(self.conv15(y5) + y4))\n",
    "        \n",
    "        #Residual Stack 6\n",
    "        y4 = self.conv16(y6)\n",
    "        y5 = F.relu(self.conv17(y4))\n",
    "        y6 = self.maxpool(F.relu(self.conv18(y5) + y4))\n",
    "        \n",
    "        y7 = torch.flatten(y6,1)\n",
    "        y8 = self.classifier(y7)\n",
    "        \n",
    "        return y8\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optimizer, Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "resnet33_new(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv6): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv7): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv8): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv9): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv10): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv11): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv12): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv13): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv14): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv15): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv16): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv17): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv18): Sequential(\n",
      "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "137514\n",
      "conv1.0.weight                          \ttorch.Size([32, 1, 3])        \t        96\n",
      "conv1.0.bias                            \ttorch.Size([32])              \t        32\n",
      "conv1.1.weight                          \ttorch.Size([32])              \t        32\n",
      "conv1.1.bias                            \ttorch.Size([32])              \t        32\n",
      "conv2.0.weight                          \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv2.0.bias                            \ttorch.Size([32])              \t        32\n",
      "conv2.1.weight                          \ttorch.Size([32])              \t        32\n",
      "conv2.1.bias                            \ttorch.Size([32])              \t        32\n",
      "conv3.0.weight                          \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv3.0.bias                            \ttorch.Size([32])              \t        32\n",
      "conv3.1.weight                          \ttorch.Size([32])              \t        32\n",
      "conv3.1.bias                            \ttorch.Size([32])              \t        32\n",
      "conv4.0.weight                          \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv4.0.bias                            \ttorch.Size([32])              \t        32\n",
      "conv4.1.weight                          \ttorch.Size([32])              \t        32\n",
      "conv4.1.bias                            \ttorch.Size([32])              \t        32\n",
      "conv5.0.weight                          \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv5.0.bias                            \ttorch.Size([32])              \t        32\n",
      "conv5.1.weight                          \ttorch.Size([32])              \t        32\n",
      "conv5.1.bias                            \ttorch.Size([32])              \t        32\n",
      "conv6.0.weight                          \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv6.0.bias                            \ttorch.Size([32])              \t        32\n",
      "conv6.1.weight                          \ttorch.Size([32])              \t        32\n",
      "conv6.1.bias                            \ttorch.Size([32])              \t        32\n",
      "conv7.0.weight                          \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv7.0.bias                            \ttorch.Size([32])              \t        32\n",
      "conv7.1.weight                          \ttorch.Size([32])              \t        32\n",
      "conv7.1.bias                            \ttorch.Size([32])              \t        32\n",
      "conv8.0.weight                          \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv8.0.bias                            \ttorch.Size([32])              \t        32\n",
      "conv8.1.weight                          \ttorch.Size([32])              \t        32\n",
      "conv8.1.bias                            \ttorch.Size([32])              \t        32\n",
      "conv9.0.weight                          \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv9.0.bias                            \ttorch.Size([32])              \t        32\n",
      "conv9.1.weight                          \ttorch.Size([32])              \t        32\n",
      "conv9.1.bias                            \ttorch.Size([32])              \t        32\n",
      "conv10.0.weight                         \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv10.0.bias                           \ttorch.Size([32])              \t        32\n",
      "conv10.1.weight                         \ttorch.Size([32])              \t        32\n",
      "conv10.1.bias                           \ttorch.Size([32])              \t        32\n",
      "conv11.0.weight                         \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv11.0.bias                           \ttorch.Size([32])              \t        32\n",
      "conv11.1.weight                         \ttorch.Size([32])              \t        32\n",
      "conv11.1.bias                           \ttorch.Size([32])              \t        32\n",
      "conv12.0.weight                         \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv12.0.bias                           \ttorch.Size([32])              \t        32\n",
      "conv12.1.weight                         \ttorch.Size([32])              \t        32\n",
      "conv12.1.bias                           \ttorch.Size([32])              \t        32\n",
      "conv13.0.weight                         \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv13.0.bias                           \ttorch.Size([32])              \t        32\n",
      "conv13.1.weight                         \ttorch.Size([32])              \t        32\n",
      "conv13.1.bias                           \ttorch.Size([32])              \t        32\n",
      "conv14.0.weight                         \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv14.0.bias                           \ttorch.Size([32])              \t        32\n",
      "conv14.1.weight                         \ttorch.Size([32])              \t        32\n",
      "conv14.1.bias                           \ttorch.Size([32])              \t        32\n",
      "conv15.0.weight                         \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv15.0.bias                           \ttorch.Size([32])              \t        32\n",
      "conv15.1.weight                         \ttorch.Size([32])              \t        32\n",
      "conv15.1.bias                           \ttorch.Size([32])              \t        32\n",
      "conv16.0.weight                         \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv16.0.bias                           \ttorch.Size([32])              \t        32\n",
      "conv16.1.weight                         \ttorch.Size([32])              \t        32\n",
      "conv16.1.bias                           \ttorch.Size([32])              \t        32\n",
      "conv17.0.weight                         \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv17.0.bias                           \ttorch.Size([32])              \t        32\n",
      "conv17.1.weight                         \ttorch.Size([32])              \t        32\n",
      "conv17.1.bias                           \ttorch.Size([32])              \t        32\n",
      "conv18.0.weight                         \ttorch.Size([32, 32, 3])       \t      3072\n",
      "conv18.0.bias                           \ttorch.Size([32])              \t        32\n",
      "conv18.1.weight                         \ttorch.Size([32])              \t        32\n",
      "conv18.1.bias                           \ttorch.Size([32])              \t        32\n",
      "classifier.0.weight                     \ttorch.Size([128, 512])        \t     65536\n",
      "classifier.0.bias                       \ttorch.Size([128])             \t       128\n",
      "classifier.2.weight                     \ttorch.Size([128, 128])        \t     16384\n",
      "classifier.2.bias                       \ttorch.Size([128])             \t       128\n",
      "classifier.4.weight                     \ttorch.Size([10, 128])         \t      1280\n",
      "classifier.4.bias                       \ttorch.Size([10])              \t        10\n"
     ]
    }
   ],
   "source": [
    "#trainset\n",
    "#testset\n",
    "N, C, L, W, modulation_classes = 4,1,1024,1,10\n",
    "#x = torch.randn(N,C,L)\n",
    "#y = torch.randn(N, modulation_classes)\n",
    "training = True\n",
    "learning_rate =  1e-3\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#Instantiate Model\n",
    "model = resnet33_new()\n",
    "model.to(device)\n",
    "\n",
    "#Print Model for reference\n",
    "print(model)\n",
    "\n",
    "train_data = iter(trainloader) #train_data is a list of 12500 lists. Each list is [input tensor, label tensor]. Input tensor is of size(4,3,32,32), output tensor is of size(4)\n",
    "test_data = iter(testloader)\n",
    "\n",
    "#print(train_data.next()[1].size())\n",
    "\n",
    "#Print number of parameters\n",
    "print(sum([param.nelement() for param in model.parameters()]))\n",
    "    \n",
    "for name, param in model.named_parameters():\n",
    "    #if param.requires_grad:\n",
    "    print('{:s}\\t{:s}\\t{:s}'.format(name.ljust(40), str(param.size()).ljust(30), str(param.nelement()).rjust(10)))\n",
    "\n",
    "#Define Loss function\n",
    "#criterion = torch.nn.MSELoss(reduction='sum')\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#Define optimizer\n",
    "#SGD\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-5)\n",
    "#Adam's algo\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=opt.wd) #What is opt? looks like torch.opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.709\n",
      "[1,  4000] loss: 0.557\n",
      "[1,  6000] loss: 0.303\n",
      "[1,  8000] loss: 0.220\n",
      "[1, 10000] loss: 0.180\n",
      "[1, 12000] loss: 0.148\n",
      "[1, 14000] loss: 0.143\n",
      "[2,  2000] loss: 0.122\n",
      "[2,  4000] loss: 0.116\n",
      "[2,  6000] loss: 0.103\n",
      "[2,  8000] loss: 0.103\n",
      "[2, 10000] loss: 0.113\n",
      "[2, 12000] loss: 0.095\n",
      "[2, 14000] loss: 0.098\n",
      "[3,  2000] loss: 0.080\n",
      "[3,  4000] loss: 0.076\n",
      "[3,  6000] loss: 0.075\n",
      "[3,  8000] loss: 0.074\n",
      "[3, 10000] loss: 0.069\n",
      "[3, 12000] loss: 0.073\n",
      "[3, 14000] loss: 0.080\n",
      "[4,  2000] loss: 0.062\n",
      "[4,  4000] loss: 0.061\n",
      "[4,  6000] loss: 0.063\n",
      "[4,  8000] loss: 0.056\n",
      "[4, 10000] loss: 0.057\n",
      "[4, 12000] loss: 0.055\n",
      "[4, 14000] loss: 0.061\n",
      "[5,  2000] loss: 0.049\n",
      "[5,  4000] loss: 0.044\n",
      "[5,  6000] loss: 0.053\n",
      "[5,  8000] loss: 0.051\n",
      "[5, 10000] loss: 0.050\n",
      "[5, 12000] loss: 0.054\n",
      "[5, 14000] loss: 0.051\n",
      "[6,  2000] loss: 0.042\n",
      "[6,  4000] loss: 0.040\n",
      "[6,  6000] loss: 0.041\n",
      "[6,  8000] loss: 0.045\n",
      "[6, 10000] loss: 0.047\n",
      "[6, 12000] loss: 0.052\n",
      "[6, 14000] loss: 0.044\n",
      "[7,  2000] loss: 0.031\n",
      "[7,  4000] loss: 0.037\n",
      "[7,  6000] loss: 0.041\n",
      "[7,  8000] loss: 0.046\n",
      "[7, 10000] loss: 0.037\n",
      "[7, 12000] loss: 0.038\n",
      "[7, 14000] loss: 0.036\n",
      "[8,  2000] loss: 0.030\n",
      "[8,  4000] loss: 0.035\n",
      "[8,  6000] loss: 0.035\n",
      "[8,  8000] loss: 0.030\n",
      "[8, 10000] loss: 0.034\n",
      "[8, 12000] loss: 0.030\n",
      "[8, 14000] loss: 0.038\n",
      "[9,  2000] loss: 0.022\n",
      "[9,  4000] loss: 0.026\n",
      "[9,  6000] loss: 0.034\n",
      "[9,  8000] loss: 0.026\n",
      "[9, 10000] loss: 0.028\n",
      "[9, 12000] loss: 0.034\n",
      "[9, 14000] loss: 0.037\n",
      "[10,  2000] loss: 0.028\n",
      "[10,  4000] loss: 0.026\n",
      "[10,  6000] loss: 0.021\n",
      "[10,  8000] loss: 0.023\n",
      "[10, 10000] loss: 0.025\n",
      "[10, 12000] loss: 0.028\n",
      "[10, 14000] loss: 0.030\n",
      "5004.496819131001\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.process_time()\n",
    "for epoch in range(0,10): #training steps\n",
    "    running_loss = 0.0\n",
    "    for i,data in enumerate(trainloader,0): #Loop through data\n",
    "        inputs, labels = data[0].to(device), data[1].to(device) #Batch size of 4\n",
    "        inputs_new = torch.zeros([4,1,32,32], dtype=torch.float32, device=device)\n",
    "        inputs_new[:,:,2:30,2:30] = inputs\n",
    "        inputs_new = inputs_new.reshape(4,1,1024)\n",
    "\n",
    "        outputs = model(inputs_new) #Get output\n",
    "        \n",
    "        loss = criterion(outputs, labels)#Get loss\n",
    "        \n",
    "        #optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward() #Back propagation\n",
    "        \n",
    "        #optimizer.step()\n",
    "        \n",
    "        #print(loss.item())\n",
    "        #print('Hello World before')\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        #print('Hello World mid')\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= learning_rate*param.grad\n",
    "            \n",
    "        \n",
    "        #print('Hello World after')\n",
    "        #print(learning_rate)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        \n",
    "toc = time.process_time()           \n",
    "print(toc-tic)\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "#Save Network\n",
    "#PATH = './cifar_net.pth'\n",
    "#torch.save(net.state_dict(), PATH) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class wise accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     0 : 99.285714 %\n",
      "Accuracy of     1 : 99.207048 %\n",
      "Accuracy of     2 : 98.643411 %\n",
      "Accuracy of     3 : 98.316832 %\n",
      "Accuracy of     4 : 98.879837 %\n",
      "Accuracy of     5 : 98.991031 %\n",
      "Accuracy of     6 : 98.747390 %\n",
      "Accuracy of     7 : 98.638132 %\n",
      "Accuracy of     8 : 99.486653 %\n",
      "Accuracy of     9 : 96.630327 %\n"
     ]
    }
   ],
   "source": [
    "#Save Network\n",
    "PATH = './resnet33_new_relu.pth'\n",
    "torch.save(model.state_dict(), PATH) \n",
    "\n",
    "model1 = resnet33_new()\n",
    "model1.to(device)\n",
    "model1.load_state_dict(torch.load(PATH))\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        images_new = torch.zeros([4,1,32,32], dtype=torch.float32, device=device)\n",
    "        images_new[:,:,2:30,2:30] = images\n",
    "        images_new = images_new.reshape(4,1,1024) \n",
    "        outputs = model1(images_new)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %f %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total accuracy across all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.680000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        images_new = torch.zeros([4,1,32,32], dtype=torch.float32, device=device)\n",
    "        images_new[:,:,2:30,2:30] = images\n",
    "        images_new = images_new.reshape(4,1,1024) \n",
    "        outputs = model1(images_new)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
